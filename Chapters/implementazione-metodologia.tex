\chapter{Method Implementation And Results}

In this chapter the tools used, the infrastructure and method implementation and the results collected during the analysis are reviewed.

A Neural Network was trained to drive in an urban environment. Checkpoints of the network's state during the training were recorded for comparison. These stages of the network were then tested with and without a simple safety-monitor in order to provide a new point of view to study AV's behaviours.

\section{Tools and software}

\subsection{Carla Simulator}

In order to have a realistic environment, with accurate physics simulation and data sensors, the open-source simulator CARLA\cite{carla}, developed by researchers at the University of Barcellona, was used. This simulator was developed with the purpose of offering an environment where AI agents can be trained to drive, with high control of the simulation parameters and the simulation of realistic sensor, which can be tuned to increase or decrease data quality, or to inject faults.\newline
CARLA is developed with a client-server architecture in mind. The \textsl{server} is basically a game, developed with \textsl{Unreal Engine 4} in C++. C++ performances are with no doubts essential to the functionality of the server: not only the environment must be simulated (inlcuding movements of pedestrians/vehicles, weather simulation\dots), but also all the data needed from the sensors attached to the system.\newline


======================================================================================

IMMAGINE CARLA

======================================================================================

CARLA is currently at version 0.9.7 and huge improvements are done at every release, gaining more attention from the experts for its realisticity. Unfortunately, when this study started, CARLA 0.9 was recently released and the tools needed for our work couldn't be found online. Thanks to the quantity of work done for the last \textit{stable} version of CARLA, 0.8.4 was used at first.\newline
Versions prior to 0.9 have some limitations on the control one has of the simulations parameters and on the data collectable from it. This doesn't impede our study, but of course limited in some way the informations on the environment and system. Some of these problems are still present in later versions of the simulator, but most of them were solved in the transition from 0.8 to 0.9.\newline\newline
One of the main problem found was with the coordinate systems. Before version 0.9, developers were using UE4's default coordinates system which is left-handed, while the standard is considered to be right-handed. This looks like not a big deal since things could be easily solved by applying a transformation matrix. However, due to performance issues (a Python client should do the real-time processng of \textsl{loads} of data at each timestep, resulting in considerable slowdowns as a result of all the processes running at the same time), it was decided to stick with the developers' decision and convert the data during analysis phase.

The 4 sensors available in CARLA 0.8 were used during the experiments. These can be easily accessed via the Python APIs provided:

\begin{itemize}
	\item Cameras
	\begin{itemize}
		\item The \textsl{"scene final"} camera provides a view of the scene (just like a regular camera)
		\item The \textsl{"depth map"} camera assigns RGB values to objects to perceive \textsl{depth} of the environment
		\item A \textsl{"semantic segmentation"} is used to classify different objects in the view by displaying them in different colors, according to the object's class
	\end{itemize}
	\item Ray-cast based Lidar
	\begin{itemize}
		\item Light Detection and Ranging is use to sense the environment and measures distance from objects by illunating the target with laser beams and measuring the time reflected light needs to "go back" to the sensor
	\end{itemize}
\end{itemize}

The three cameras were used during the training phase of the network. Three \textsl{"scene final"} cameras are attached to the car to actually \textsl{see} the environment (one on the front and 1 per side). These cameras, combined with the \textsl{"depth map"} camera allows not only the car to see, but also to perceive distances from objects in the scenario.
The \textsl{"semantic segmentation"} provides image classification features by querying the server for ground-truth values. This is with no doubt a semplification of a real system, where the most powerful image-classification softwares are essentially other neural networks. At the same time a misclassification can be considered as an error of the control system: the safety monitor, combining data from all the available sensors, will not "correct" the misclassification but it must react fast and safely to avoid the potential consequences of it.

+++====    quindi pensiamo che non importi poi molto?

A ray-cast based Lidar is the only other sensor available for this version of CARLA. Parameters of this sensor can be easily tuned to simulate real lidars such as the \textsl{Velodyne LiDAR} or to simulate faults such as low data quality, noisy data or data loss\dots
The most important editable parameters are:

\begin{itemize}
	\item Channels
	\begin{itemize}
		\item The number of laser beams used by the system. These lasers are distributed over the vertical axis. The more the lasers are, the more accurate will be the scannings
	\end{itemize}
	\item Range
	\begin{itemize}
		\item Lasers' range in meters
	\end{itemize}
	\item Rotation Frequency
	\begin{itemize}
		\item This parameters define the rotation frequency (in Hz) of the scanning beams.
	\end{itemize}
	\item Points Per Second
	\begin{itemize}
		\item The actual number of points generated each frame by the sensor
	\end{itemize}
	\item Vertical FOV limits
	\begin{itemize}
		\item Maximum and minimum height of the scannings
	\end{itemize}
	
\end{itemize}


\begin{itemize}
	\item CARLA
	\item Nervana Systems - coach (Intel)
	\item Reti neurali su git
	\item Monitor
\end{itemize}


\section{Method Implementation}

Dedicare una sezione alle decisioni prese?

\section{Results}

\begin{itemize}
	
	\item Interazione rete-monitor
	\item Safety Monitor Implementation - obstacle detection
	\item Come vengono raccolti i dati
	\item Come vengono preprocessati
	
\end{itemize}

