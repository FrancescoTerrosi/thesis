\chapter{Method Implementation And Results}

In this chapter the tools used, the infrastructure and method implementation and the results collected during the analysis are reviewed.

A Neural Network was trained to drive in an urban environment. Checkpoints of the network's state during the training were recorded for comparison. These stages of the network were then tested with and without a simple safety-monitor in order to provide a new point of view to study AV's behaviours.

\section{Tools and software}

\subsection{Carla Simulator}

In order to have a realistic environment, with accurate physics simulation and data sensors, the open-source simulator CARLA\cite{carla}, developed by researchers at the University of Barcellona, was used. This simulator was developed with the purpose of offering an environment where AI agents can be trained to drive, with high control of the simulation parameters and the simulation of realistic sensor, which can be tuned to increase or decrease data quality, or to inject faults.\newline
CARLA is developed with a client-server architecture in mind. The \textsl{server} is basically a game, developed with \textsl{Unreal Engine 4} in C++. C++ performances are with no doubts essential to the functionality of the server: not only the environment must be simulated (inlcuding movements of pedestrians/vehicles, weather simulation\dots), but also all the data needed from the sensors attached to the system.\newline


======================================================================================

IMMAGINE CARLA

======================================================================================

CARLA is currently at version 0.9.7 and huge improvements are done at every release, gaining more attention from the experts for its realisticity. Unfortunately, when this study started, CARLA 0.9 was recently released and the tools needed for our work couldn't be found online. Thanks to the quantity of work done for the last \textit{stable} version of CARLA, 0.8.4 was used at first.\newline
Versions prior to 0.9 have some limitations on the control one has of the simulations parameters and on the data collectable from it. This doesn't impede our study, but of course limited in some way the informations on the environment and system. Some of these problems are still present in later versions of the simulator, but most of them were solved in the transition from 0.8 to 0.9.\newline\newline
One of the main problem found was with the coordinate systems. Before version 0.9, developers were using UE4's default coordinates system which is left-handed, while the standard is considered to be right-handed. This looks like not a big deal since things could be easily solved by applying a transformation matrix. However, due to performance issues (a Python client should do the real-time processng of \textsl{loads} of data at each timestep, resulting in considerable slowdowns as a result of all the processes running at the same time), it was decided to stick with the developers' decision and convert the data during analysis phase.

All the sensors available in CARLA 0.8 were used during the experiments. These can be easily accessed via the Python APIs provided:

\begin{itemize}
	\item Cameras
	\begin{itemize}
		\item The \textsl{"scene final"} camera provides a view of the scene (just like a regular camera)
		\item The \textsl{"depth map"} camera assigns RGB values to objects to perceive \textsl{depth} of the environment
		\item A \textsl{"semantic segmentation"} is used to classify different objects in the view by displaying them in different colors, according to the object's class
	\end{itemize}
	\item Ray-cast based Lidar
\end{itemize}

The three cameras were used during the training phase of the network. Three \textsl{"scene final"} cameras are attached to the car to actually \textsl{see} the environment (one on the front and 1 per side). These cameras, combined with the \textsl{"depth map"} camera allows not only the car to see, but also to perceive distances from objects in the scenario.
The \textsl{"semantic segmentation"} provides image classification features by querying the server for ground-truth values. This is with no doubt a semplification of a real system, where the most powerful image-classification softwares are essentially neural networks. A misclassification could lead to catastrophic failures but we are not interested in their accuracy: the system's safety monitor, combining data from all the available sensors, will not "correct" the misclassification but it must react fast and safely to the consequences of it.




\begin{itemize}
	\item CARLA
	\item Nervana Systems - coach (Intel)
	\item Reti neurali su git
	\item Monitor
\end{itemize}


\section{Method Implementation}

Dedicare una sezione alle decisioni prese?

\section{Results}

\begin{itemize}
	
	\item Interazione rete-monitor
	\item Safety Monitor Implementation - obstacle detection
	\item Come vengono raccolti i dati
	\item Come vengono preprocessati
	
\end{itemize}

