\chapter{System Analysis Method}

In this chapter is presented a method to study the safety level of an autonomous car over time, observing the emergence resulting from the interactions of a neural network controller and a safety monitor in a simulated environment.\newline
A neural network was trained, tested and trained again several times with and without the safety monitor, to collect data about the emergence of these components.

\section{Experimental Environment and Measures}

The goal of this work is to develop and to assess the feasability of an experimental method for the safety assessment of an autonomous vehicle. Due to the system being composed by two constituent systems: the Controller and the Checker, we think that a point of view based on the emergent behaviour resulting from the interaction of these systems can improve the quality of the assessment.\newline
The main aspects we are interested in are:

\begin{itemize}
	\item How the coverage of the system changes when the same monitor is applied to different stages of a network
	\item Changes in the safety gain provided by the same monitor when applied to different networks
	\item What features of the monitor determine an improvement (or worsening) to the safety of the system
	\item Possible behaviours of the neural network having an impact on the monitor usefulness
\end{itemize}

At the system level, we are interested in the probability of a safety-failure (e.g. a crash) and how to minimize it, or in the safety of the system as a result of the training of a neural network, the Controller and a fault tolerance mechanism, the Monitor. As long as the network is trained properly, we expect that $P_{C_{i}}(failure) \geq P_{C_{i+t}}(failure)$ where $C_{i}$ represents a neural network controller trained for $i$ epochs. At the same time we want our safety monitor to provide at least the same level of fault tolerance if the same network is trained again for $t$ epochs.\newline
The analysis must start with the definition of $n_{h=0\dots}$ safety cases, where $n$ is the effective number of cases and $h$ is difficulty of the initial conditions. $C_{i}$ is tested in all the scenarios, starting with conditions somehow \textsl{"favorable"} to the system and then increasing the difficulty(e.g. increasing the traffic in the scenario and/or simulating a bad weather). This method allows to observe the \textsl{Time To Failure} of the Controller under different points of view:

\begin{itemize}
	\item $TTF_{i,j_{h}}$ as the time in which the controller fails at epoch $i$ in the ${j_{h}}^{th}$ scenario
	\item $MTTF_{i,h}$, mean time to failure when the system performs in different level of difficulty 
	\item $MTTF_{Controller_{i}} = \frac{1}{n} \sum_{k = 0}^{n} TTF_{i,k}$
\end{itemize}

The controller is then trained again and re-tested in the same scenarios. 

Since we are working in a simulated environment, the time to failure was computed using simulations steps, without loss of generality.\newline 

-------------------------------------------------------------------        FATTO CHE PROB INCIDENTE SOMMI A 1. COME LO ESPRIMO?\newline

One of the main problem realated to assessing AVs' safety is the execution time. The probability of a failure increases monotonically over time, but the increasing factor should be lower the more the network is trained, so variation on the hardness of scenarios must be designed accurately. This property could result in very long simulations, but it also gives a useful hint for checking whether the system's safety is improving or not. \newline\newline
Once trained neural networks become essentially black boxes and even a small variation on the training parameters could result in totally different behaviours during test phase, therefore it can not be assumed that the same software (the monitor) will provide the same level of safety.\newline
The monitor must be tested in the same scenarios in which the controller was tested and should not intervene during the simulation, but at the rigth time needed to prevent the failure event if the controller failed the scenario. The simulations previously recorded are now repeated with the monitor activated and the following measures are extracted:

\begin{itemize}
	\item True Positive Rate
	\begin{itemize}
		\item Rate of successful failure avoidance where the controller failed.
	\end{itemize}
	\item False Positive Rate
	\begin{itemize}
		\item Rate of the events in which there's no failure but Monitor raises alarm. It is important that the fault-tolerance mechanism is not activated or the simulation will be compromised
	\end{itemize}
	\item False Negative Rate
	\begin{itemize}
		\item Rate of failures in the controller not detected by the monitor
	\end{itemize}
\end{itemize}

Of course we desire the monitor's detections to be the most accurate possible. For this reason \textsl{Sensitivity}\footnote{True Positive rate: the proportion of safety measures applied by the monitor when actually needed} and False Negative rate were chosen as measures of interest.\newline
While in most of the cases a false positive will result in a state of degraded service, since a self-driving car is a safety-critical system performing in a dynamic environment, a false positive could put the system in an unsafe state (imagine performing an emergency brake for no reason on the highway), so False positive rate was taken into account as well.\newline
However, these measures themselves aren't sufficient to detect changes in the interaction between the two CSs, so it's useful to record data such as the vehicle's speed and the controller's throttling/steering and to combine them with data recorded from the monitor to detect possible correlations between the behaviours.
These values must be recomputed not only when the Monitor is improved (either by implementing a more sophisticated detection method or by improving the quality of sensors) but also when the network is trained because/due to...
=============================================================================================
GIUSTIFICARE QUI IL DISCORSO FAMOSO O RIMANDARE A CAPITOLO PRECEDENTE SU LETTERATURA?
==============================================================================================

When all the data are collected for each scenario

\section{Experiments methodology}

In this section we propose and describe the methodology developed in this work.\newline

The study consists of several experiments in a simulated realistic environment, in which we observe how the coverage of the safety-monitor (i.e. the probability of raising an alert if there really is a safety-hazard) varies with respect to a neural network \textsl{in different stages of training}.\newline
The first step to perform the analysis is to define what are the metrics of interest.

	\begin{itemize}
		
		\item Come vengono effettuati gli esperimenti (scenari? durata fissa? ad oltranza? fino ad un fallimento? \dots)
		
	\end{itemize}

The efficacy of the constituent systems was studied separately at first. Since the goal of a vehicle is to go from point A to point B without crashing or hitting a pedestrian, the controller was tested at first, recording the the actions performed 